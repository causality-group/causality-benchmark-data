{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and System Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "from typing import List, Optional\n",
    "\n",
    "# Third paty libraries\n",
    "import pandas as pd\n",
    "\n",
    "def project_root_path() -> str:\n",
    "    notebook_root_path = os.path.abspath(\"\")\n",
    "    return os.path.dirname(notebook_root_path)\n",
    "\n",
    "project_path = project_root_path()\n",
    "\n",
    "print(f'Project root path: {project_path}')\n",
    "print(f'Python version: {sys.version}')\n",
    "\n",
    "sys.path.append(project_path)\n",
    "\n",
    "\n",
    "# Causality libraries\n",
    "from analysis.compounding import *\n",
    "from analysis.evaluate_pnl import *\n",
    "from data.dataloader import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_path = '~/data/causality_benchmark_dataset/common/daily/usa/1500/20240124'\n",
    "\n",
    "backtest_offset = pd.offsets.BDay(1)  #  pd.offsets.Week(1) # pd.offsets.MonthBegin(1)  # \n",
    "\n",
    "# 4+ years of out-of-sample period:\n",
    "backtest_end_ts = pd.Timestamp('2020-01-01')  # None # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames are indexed such that values in a row are observable on the date of the corresponding index.\n",
    "# For prices this means prices of the given date, while for returns it means that the return is finishing on the index date.\n",
    "\n",
    "# Close to Close (overnight+intraday) returns are adjusted for splits, dividends, mergers and aquisitions:\n",
    "ret_cc_df = load_field_df('ret_cc', data_root_path, end_ts=backtest_end_ts)\n",
    "# Can't trade the close auction based on the same close price.\n",
    "# Let's generate **adjusted** close to next day 15:45 returns, which can be used to trade in the upcoming close auction:\n",
    "price_close_df = load_field_df('close', data_root_path, end_ts=backtest_end_ts)  # close prices are un-adjusted\n",
    "\n",
    "price_1545_df = load_field_df('154500_close_5m', data_root_path, end_ts=backtest_end_ts) # intraday prices are un-adjusted\n",
    "# Same day prices, no need for onvernight adjustements:\n",
    "ret_1545c_df = price_close_df / price_1545_df - 1.0\n",
    "# Close to Close (cc) returns are already adjusted for overnight events, let's use those as a base line:\n",
    "ret_c1545_df = np.exp(np.log(ret_cc_df + 1.0) - np.log(ret_1545c_df + 1.0)) - 1.0\n",
    "\n",
    "# Universe is generated using liquidity data of previos days, but it's meant to be the universe one day later, on the index date.\n",
    "# Contains 1.0 on days when an asset is tradeable, and np.NaN otherwise:\n",
    "universe_df = load_field_df('universe', data_root_path, shift=0, end_ts=backtest_end_ts)\n",
    "\n",
    "# All data fields from disk have the same index and same columns:\n",
    "daily_index = universe_df.index\n",
    "\n",
    "print(f'Loaded {len(daily_index)} daily records and {len(universe_df.columns)} assets.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Trading Bars\n",
    "\n",
    "Variables names include \"bar\", in contrast to the daily data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish bar_tss, serving as boundaries of trading periods\n",
    "\n",
    "if backtest_offset in [pd.offsets.Day(1), pd.offsets.BDay(1)]:\n",
    "    bar_tss = list(daily_index)\n",
    "else:\n",
    "    current_ts = daily_index[0] - pd.offsets.Day(1) + backtest_offset\n",
    "    # List of Timestamps:\n",
    "    bar_tss = [daily_index[daily_index >= current_ts][0]]\n",
    "    current_ts += backtest_offset\n",
    "    while current_ts <= daily_index[-1]:\n",
    "        bar_tss += [daily_index[daily_index >= current_ts][0]]\n",
    "        current_ts += backtest_offset\n",
    "\n",
    "    # Keep unique elements in the list, while staying sorted:\n",
    "    bar_tss = sorted(list(set(bar_tss)))\n",
    "\n",
    "assert len(bar_tss) == len(set(bar_tss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar plot with bars on the days which are in bar_tss:\n",
    "\n",
    "y_values = [\n",
    "    (ts in bar_tss) * 1.0\n",
    "    for ts in daily_index\n",
    "]\n",
    "x_values = daily_index\n",
    "df = pd.DataFrame(y_values, index=[str(ts).split(' ')[0] for ts in daily_index], columns=['Trading'])\n",
    "# Bar plot:\n",
    "df.iloc[:100, :].plot(\n",
    "    kind='bar', \n",
    "    figsize=(20, 1), \n",
    "    xlabel='Dates in Raw Data', \n",
    "    ylabel='Trading Day Flag', \n",
    "    title='First 100 Days',\n",
    "    legend=False,\n",
    ")\n",
    "_ = df.iloc[-100:, :].plot(\n",
    "    kind='bar', \n",
    "    figsize=(20, 1), \n",
    "    xlabel='Dates in Raw Data', \n",
    "    ylabel='Trading Day Flag',\n",
    "    title='Last 100 Days',\n",
    "    legend=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample returns between Timestamps in bar_tss, by compounding returns between timestamps in bar_tss.\n",
    "# Upcoming and observabel returns match, such that we can causally trade signals using the returns of the sime timestamp:\n",
    "# For example the simplest possible backtest, placing $1 on each asset that lost in the period before will look like:\n",
    "# pnl_df = (observable_bar_ret_cc_df < 0.0) * upcoming_bar_ret_cc_df\n",
    "\n",
    "def compound_upcoming_bar_return_cc_df(\n",
    "    ret_cc_df: pd.DataFrame, \n",
    "    bar_tss: List[pd.Timestamp]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compounds daily adjusted close to close returns for each Timestamp in bar_tss, \n",
    "    such that we can trade those at the 16:00 auction.\n",
    "    \n",
    "    Returns bars do not overlap, each covers a time period from 16:00 between bar_tss[i] and bar_tss[i+1].\n",
    "    \"\"\"\n",
    "    # Returns end on the index date, need to align to the start date of the return\n",
    "    ret_cc_df = ret_cc_df.shift(-1)   \n",
    "    ret_cc_df = np.log(ret_cc_df + 1.0)  # convert to log returns\n",
    "    bar_tss = bar_tss + [pd.Timestamp.max]\n",
    "    log_bar_ret_df = pd.DataFrame(\n",
    "        {\n",
    "            # Indexing my Timestamp is inclusive, hence: .iloc[:-1, :]\n",
    "            ts: ret_cc_df.loc[ts:bar_tss[i+1], :].iloc[:-1, :].sum()\n",
    "            for i, ts in enumerate(bar_tss[:-1])\n",
    "        }\n",
    "    ).T\n",
    "    return np.exp(log_bar_ret_df) - 1.0\n",
    "\n",
    "def compound_observable_bar_return_cc_df(\n",
    "    ret_cc_df: pd.DataFrame, \n",
    "    bar_tss: List[pd.Timestamp],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compounds daily adjusted close to close returns for each Timestamp in bar_tss, \n",
    "    such that we can observe those at 15:45 to trade the 16:00 auction.\n",
    "\n",
    "    This means in practice using close prices only until previous close.\n",
    "    \n",
    "    Returns bars do not overlap, each covers a time period from 16:00 \n",
    "    between bar_tss[i] and bar_tss[i+1].\n",
    "    \"\"\"\n",
    "    \n",
    "    ret_cc_df = np.log(ret_cc_df + 1.0)  # convert to log returns\n",
    "    bar_tss = [pd.Timestamp.min] + bar_tss\n",
    "    log_bar_ret_df = pd.DataFrame(\n",
    "        {\n",
    "            # Indexing my Timestamp is inclusive, hence: .iloc[:-1, :]\n",
    "            ts: ret_cc_df.loc[bar_tss[i-1]:ts, :].iloc[:-1, :].sum()\n",
    "            for i, ts in enumerate(bar_tss)\n",
    "            if i > 0\n",
    "        }\n",
    "    ).T\n",
    "    return np.exp(log_bar_ret_df) - 1.0\n",
    "\n",
    "upcoming_bar_ret_cc_df = compound_upcoming_bar_return_cc_df(ret_cc_df, bar_tss)\n",
    "observable_bar_ret_cc_df = compound_observable_bar_return_cc_df(ret_cc_df, bar_tss)\n",
    "\n",
    "bar_universe_df = universe_df.loc[bar_tss, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the data used in the trading strategy at Timestamps in bat_tss, \n",
    "# available at the Timestamp in its index (observable_ prefix)\n",
    "\n",
    "# Variables observable when trading on the bar_tss dates:\n",
    "observable_ret_c1545_df = ret_c1545_df.loc[bar_tss, :]  # Can use the current 15:45 price\n",
    "observable_bar_ret_cc1545_df = compound_ret_df(observable_bar_ret_cc_df, ret_c1545_df.loc[bar_tss, :])\n",
    "\n",
    "observable_bar_signal_dfdict = {\n",
    "    # Return from last daily close to today's 15:45 price:\n",
    "    'day_ret_c1545': observable_ret_c1545_df,\n",
    "    # Returns of period bar until previous close, compounded with returns until 15:45 from previous close:\n",
    "    'bar_ret_cc1545': observable_bar_ret_cc1545_df,\n",
    "}\n",
    "\n",
    "for window_i in (1, 2, 3, 5, 21, 42, 63, int(252 / 2), 252):  # Conveniently sparse windows to reduce correlation\n",
    "    observable_bar_signal_dfdict[f'bar_ret_cc_{window_i:03d}'] = observable_bar_ret_cc_df.rolling(window=window_i).sum().loc[bar_tss, :]\n",
    "for window_i in (1, 2, 3, 5, 21, 42, 63, int(252 / 2), 252):  # Conveniently sparse windows to reduce correlation\n",
    "    observable_bar_signal_dfdict[f'bar_ret^2_cc_{window_i:03d}'] = observable_bar_ret_cc_df.rolling(window=window_i).sum().loc[bar_tss, :] ** 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a backtest loop, to make trading dacisions on each day in bar_tss\n",
    "\n",
    "# for trade_ts in bar_tss:\n",
    "#     print(f'Trading the close on {trade_ts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signalbacktest_df(signal_df, upcoming_ret_df, enter_at_stdev=2.0):\n",
    "    \"\"\"A simple backtest, trading cross-sectional signals at a given standard deviation.\n",
    "\n",
    "    Invests $0.5 both long and short, hence results can be interpreted as strategy returns.\n",
    "\n",
    "    Args:\n",
    "        signal_df: DataFrame with signals observable at the Timestamps in in its index.\n",
    "        upcoming_ret_df: DataFrame with forward looking returns tradeable at the Timestamps in in its index.\n",
    "        enter_at_stdev: Number of standard deviations to enter the trade both on long and short side.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with strategy returns.\n",
    "    \"\"\"\n",
    "    is_long_df = signal_df.add(-(signal_df.mean(axis=1) + enter_at_stdev * signal_df.std(axis=1)), axis=0) > 0.0\n",
    "    is_short_df = signal_df.add(-(signal_df.mean(axis=1) - enter_at_stdev * signal_df.std(axis=1)), axis=0) < 0.0\n",
    "\n",
    "    signal_df = is_long_df.astype(int) - is_short_df.astype(int)\n",
    "    # Demean cross-sectionally:\n",
    "    signal_df = signal_df.add(-signal_df.mean(axis=1), axis=0)\n",
    "    # Normalize cross-sectionally:\n",
    "    signal_df = signal_df.div(signal_df.abs().sum(axis=1), axis=0)\n",
    "\n",
    "    return signal_df * upcoming_ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl_dict = {}\n",
    "\n",
    "enter_at_stdev = 2.0\n",
    "\n",
    "for key, signal_df in observable_bar_signal_dfdict.items():\n",
    "\n",
    "    signal_df = signal_df * bar_universe_df\n",
    "    trade_ret_df = signalbacktest_df(signal_df, upcoming_bar_ret_cc_df, enter_at_stdev=2.0)\n",
    "    pnl_dict[key] = trade_ret_df.sum(axis=1)\n",
    "\n",
    "strategy_pnl_df = pd.DataFrame(pnl_dict)\n",
    "\n",
    "plot_pnl(strategy_pnl_df)\n",
    "display(calculate_performance_df(strategy_pnl_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cauality-forecast-darts-p3.9",
   "language": "python",
   "name": "cauality-forecast-darts-p3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
