{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and System Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Third paty libraries\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def project_root_path() -> str:\n",
    "    notebook_root_path = os.path.abspath(\"\")\n",
    "    return os.path.dirname(notebook_root_path)\n",
    "\n",
    "\n",
    "project_path = project_root_path()\n",
    "\n",
    "print(f\"Project root path: {project_path}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "sys.path.append(project_path)\n",
    "\n",
    "\n",
    "# Causality libraries\n",
    "from analysis.backtest import signalbacktest_df\n",
    "from analysis.compounding import *\n",
    "from analysis.evaluate_pnl import *\n",
    "from data.dataloader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_path = \"~/data/causality_benchmark_dataset/common/daily/usa/1500/20240124\"\n",
    "\n",
    "backtest_offset = pd.offsets.BDay(\n",
    "    1\n",
    ")  #  pd.offsets.Week(1) # pd.offsets.MonthBegin(1)  #\n",
    "\n",
    "# Leaving 3+ years of out-of-sample period:\n",
    "backtest_end_ts = pd.Timestamp('2021-01-01')  # None # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames are indexed such that values in a row are observable on the date of the corresponding index.\n",
    "# For prices this means prices of the given date, while for returns it means that the return is finishing on the index date.\n",
    "\n",
    "# Close to Close (overnight+intraday) returns are adjusted for splits, dividends, mergers and aquisitions:\n",
    "ret_cc_df = load_field_df(\"ret_cc\", data_root_path, end_ts=backtest_end_ts)\n",
    "# Can't trade the close auction based on the same close price.\n",
    "# Let's generate **adjusted** close to next day 15:45 returns, which can be used to trade in the upcoming close auction:\n",
    "price_close_df = load_field_df(\n",
    "    \"close\", data_root_path, end_ts=backtest_end_ts\n",
    ")  # close prices are un-adjusted\n",
    "\n",
    "price_1545_df = load_field_df(\n",
    "    \"154500_close_5m\", data_root_path, end_ts=backtest_end_ts\n",
    ")  # intraday prices are un-adjusted\n",
    "# Same day prices, no need for onvernight adjustements:\n",
    "ret_1545c_df = price_close_df / price_1545_df - 1.0\n",
    "# Close to Close (cc) returns are already adjusted for overnight events, let's use those as a base line:\n",
    "ret_c1545_df = np.exp(np.log(ret_cc_df + 1.0) - np.log(ret_1545c_df + 1.0)) - 1.0\n",
    "\n",
    "# Universe is generated using liquidity data of previos days, but it's meant to be the universe one day later, on the index date.\n",
    "# Contains 1.0 on days when an asset is tradeable, and np.NaN otherwise:\n",
    "universe_df = load_field_df(\"universe\", data_root_path, shift=0, end_ts=backtest_end_ts)\n",
    "\n",
    "# All data fields from disk have the same index and same columns:\n",
    "daily_index = universe_df.index\n",
    "\n",
    "print(f\"Loaded {len(daily_index)} daily records and {len(universe_df.columns)} assets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Trading Bars\n",
    "\n",
    "Variables names include \"bar\", in contrast to the daily data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish bar_tss, serving as boundaries of trading periods\n",
    "\n",
    "if backtest_offset in [pd.offsets.Day(1), pd.offsets.BDay(1)]:\n",
    "    bar_tss = list(daily_index)\n",
    "else:\n",
    "    current_ts = daily_index[0] - pd.offsets.Day(1) + backtest_offset\n",
    "    # List of Timestamps:\n",
    "    bar_tss = [daily_index[daily_index >= current_ts][0]]\n",
    "    current_ts += backtest_offset\n",
    "    while current_ts <= daily_index[-1]:\n",
    "        bar_tss += [daily_index[daily_index >= current_ts][0]]\n",
    "        current_ts += backtest_offset\n",
    "\n",
    "    # Keep unique elements in the list, while staying sorted:\n",
    "    bar_tss = sorted(list(set(bar_tss)))\n",
    "\n",
    "assert len(bar_tss) == len(set(bar_tss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar plot with bars on the days which are in bar_tss:\n",
    "\n",
    "y_values = [(ts in bar_tss) * 1.0 for ts in daily_index]\n",
    "x_values = daily_index\n",
    "df = pd.DataFrame(\n",
    "    y_values, index=[str(ts).split(\" \")[0] for ts in daily_index], columns=[\"Trading\"]\n",
    ")\n",
    "# Bar plot:\n",
    "df.iloc[:100, :].plot(\n",
    "    kind=\"bar\",\n",
    "    figsize=(20, 1),\n",
    "    xlabel=\"Dates in Raw Data\",\n",
    "    ylabel=\"Trading Day Flag\",\n",
    "    title=\"First 100 Days\",\n",
    "    legend=False,\n",
    ")\n",
    "_ = df.iloc[-100:, :].plot(\n",
    "    kind=\"bar\",\n",
    "    figsize=(20, 1),\n",
    "    xlabel=\"Dates in Raw Data\",\n",
    "    ylabel=\"Trading Day Flag\",\n",
    "    title=\"Last 100 Days\",\n",
    "    legend=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample returns between Timestamps in bar_tss, by compounding returns between timestamps in bar_tss.\n",
    "# Upcoming and observabel returns match, such that we can causally trade signals using the returns of the sime timestamp:\n",
    "# For example the simplest possible backtest, placing $1 on each asset that lost in the period before will look like:\n",
    "# pnl_df = (observable_bar_ret_cc_df < 0.0) * upcoming_bar_ret_cc_df\n",
    "\n",
    "upcoming_bar_ret_cc_df = compound_upcoming_bar_return_cc_df(ret_cc_df, bar_tss)\n",
    "observable_bar_ret_cc_df = compound_observable_bar_return_cc_df(ret_cc_df, bar_tss)\n",
    "\n",
    "bar_universe_df = universe_df.loc[bar_tss, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the data used in the trading strategy at Timestamps in bat_tss,\n",
    "# available at the Timestamp in its index (observable_ prefix)\n",
    "\n",
    "# Variables observable when trading on the bar_tss dates:\n",
    "observable_ret_c1545_df = ret_c1545_df.loc[\n",
    "    bar_tss, :\n",
    "]  # Can use the current 15:45 price\n",
    "observable_bar_ret_cc1545_df = compound_ret_df(\n",
    "    observable_bar_ret_cc_df, ret_c1545_df.loc[bar_tss, :]\n",
    ")\n",
    "\n",
    "observable_bar_signal_dfdict = {\n",
    "    # Return from last daily close to today's 15:45 price:\n",
    "    \"day_ret_c1545\": observable_ret_c1545_df,\n",
    "    # Returns of period bar until previous close, compounded with returns until 15:45 from previous close:\n",
    "    \"bar_ret_cc1545\": observable_bar_ret_cc1545_df,\n",
    "}\n",
    "\n",
    "for window_i in (\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    5,\n",
    "    21,\n",
    "    42,\n",
    "    63,\n",
    "    int(252 / 2),\n",
    "    252,\n",
    "):  # Conveniently sparse windows to reduce correlation\n",
    "    observable_bar_signal_dfdict[f\"bar_ret_cc_{window_i:03d}\"] = (\n",
    "        observable_bar_ret_cc_df.rolling(window=window_i).sum().loc[bar_tss, :]\n",
    "    )\n",
    "for window_i in (\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    5,\n",
    "    21,\n",
    "    42,\n",
    "    63,\n",
    "    int(252 / 2),\n",
    "    252,\n",
    "):  # Conveniently sparse windows to reduce correlation\n",
    "    observable_bar_signal_dfdict[f\"bar_ret^2_cc_{window_i:03d}\"] = (\n",
    "        observable_bar_ret_cc_df.rolling(window=window_i).sum().loc[bar_tss, :] ** 2.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a backtest loop, to make trading dacisions on each day in bar_tss\n",
    "\n",
    "# for trade_ts in bar_tss:\n",
    "#     print(f'Trading the close on {trade_ts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Profit & Loss (P&L) of the trading signals\n",
    "\n",
    "pnl_dict = {}\n",
    "\n",
    "enter_at_stdev = 2.0\n",
    "\n",
    "for key, signal_df in observable_bar_signal_dfdict.items():\n",
    "\n",
    "    signal_df = signal_df * bar_universe_df\n",
    "    trade_ret_df = signalbacktest_df(\n",
    "        signal_df, upcoming_bar_ret_cc_df, enter_at_stdev=2.0\n",
    "    )\n",
    "    pnl_dict[key] = trade_ret_df.sum(axis=1)\n",
    "\n",
    "strategy_pnl_df = pd.DataFrame(pnl_dict)\n",
    "\n",
    "plot_pnl(strategy_pnl_df)\n",
    "display(calculate_performance_df(strategy_pnl_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cauality-forecast-darts-p3.9",
   "language": "python",
   "name": "cauality-forecast-darts-p3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
